privacy = [{ "Model": "Baichuan-13b", "Privacy Awareness Normal (\u2191)": 0.082, "Privacy Awareness Aug (\u2191)": 0.225, "Privacy Leakage RtA (\u2191)": 0.65, "Privacy Leakage TD (\u2193)": 0.06, "Privacy Leakage CD (\u2193)": 0.11, "Privacy Awareness Correlation (\u2191)": 0.567 }, { "Model": "ChatGLM2", "Privacy Awareness Normal (\u2191)": 0.789, "Privacy Awareness Aug (\u2191)": 0.993, "Privacy Leakage RtA (\u2191)": 0.64, "Privacy Leakage TD (\u2193)": 0.13, "Privacy Leakage CD (\u2193)": 0.22, "Privacy Awareness Correlation (\u2191)": 0.248 }, { "Model": "ChatGPT", "Privacy Awareness Normal (\u2191)": 0.714, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.28, "Privacy Leakage TD (\u2193)": 0.3, "Privacy Leakage CD (\u2193)": 0.35, "Privacy Awareness Correlation (\u2191)": 0.665 }, { "Model": "ERNIE", "Privacy Awareness Normal (\u2191)": 0.911, "Privacy Awareness Aug (\u2191)": 0.993, "Privacy Leakage RtA (\u2191)": 0.89, "Privacy Leakage TD (\u2193)": 0.01, "Privacy Leakage CD (\u2193)": 0.02, "Privacy Awareness Correlation (\u2191)": 0.473 }, { "Model": "Koala-13b", "Privacy Awareness Normal (\u2191)": 0.718, "Privacy Awareness Aug (\u2191)": 0.982, "Privacy Leakage RtA (\u2191)": 0.27, "Privacy Leakage TD (\u2193)": 0.21, "Privacy Leakage CD (\u2193)": 0.32, "Privacy Awareness Correlation (\u2191)": 0.185 }, { "Model": "Llama2-7b", "Privacy Awareness Normal (\u2191)": 1.0, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.94, "Privacy Leakage TD (\u2193)": 0.02, "Privacy Leakage CD (\u2193)": 0.09, "Privacy Awareness Correlation (\u2191)": 0.101 }, { "Model": "Llama2-13b", "Privacy Awareness Normal (\u2191)": 1.0, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.98, "Privacy Leakage TD (\u2193)": 0.0, "Privacy Leakage CD (\u2193)": 0.03, "Privacy Awareness Correlation (\u2191)": 0.17 }, { "Model": "Oasst-12b", "Privacy Awareness Normal (\u2191)": 0.389, "Privacy Awareness Aug (\u2191)": 0.886, "Privacy Leakage RtA (\u2191)": 0.82, "Privacy Leakage TD (\u2193)": 0.01, "Privacy Leakage CD (\u2193)": 0.13, "Privacy Awareness Correlation (\u2191)": -0.161 }, { "Model": "Vicuna-7b", "Privacy Awareness Normal (\u2191)": 0.836, "Privacy Awareness Aug (\u2191)": 0.982, "Privacy Leakage RtA (\u2191)": 0.62, "Privacy Leakage TD (\u2193)": 0.17, "Privacy Leakage CD (\u2193)": 0.28, "Privacy Awareness Correlation (\u2191)": 0.373 }, { "Model": "Vicuna-13b", "Privacy Awareness Normal (\u2191)": 0.829, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.64, "Privacy Leakage TD (\u2193)": 0.21, "Privacy Leakage CD (\u2193)": 0.31, "Privacy Awareness Correlation (\u2191)": 0.367 }, { "Model": "Vicuna-33b", "Privacy Awareness Normal (\u2191)": 0.743, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.32, "Privacy Leakage TD (\u2193)": 0.28, "Privacy Leakage CD (\u2193)": 0.3, "Privacy Awareness Correlation (\u2191)": 0.442 }, { "Model": "Wizardlm-13b", "Privacy Awareness Normal (\u2191)": 0.979, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.87, "Privacy Leakage TD (\u2193)": 0.08, "Privacy Leakage CD (\u2193)": 0.35, "Privacy Awareness Correlation (\u2191)": 0.183 }, { "Model": "GPT-4", "Privacy Awareness Normal (\u2191)": 0.982, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.41, "Privacy Leakage TD (\u2193)": 0.33, "Privacy Leakage CD (\u2193)": 0.36, "Privacy Awareness Correlation (\u2191)": 0.634 }, { "Model": "Llama2-70b", "Privacy Awareness Normal (\u2191)": 1.0, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.86, "Privacy Leakage TD (\u2193)": 0.07, "Privacy Leakage CD (\u2193)": 0.22, "Privacy Awareness Correlation (\u2191)": 0.484 }, { "Model": "Mistral-7b", "Privacy Awareness Normal (\u2191)": 0.654, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.71, "Privacy Leakage TD (\u2193)": 0.04, "Privacy Leakage CD (\u2193)": 0.08, "Privacy Awareness Correlation (\u2191)": 0.469 }, { "Model": "PaLM 2", "Privacy Awareness Normal (\u2191)": 0.089, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.1, "Privacy Leakage TD (\u2193)": 0.26, "Privacy Leakage CD (\u2193)": 0.28, "Privacy Awareness Correlation (\u2191)": 0.572 }, { "Model": "ChatGLM3", "Privacy Awareness Normal (\u2191)": 0.034, "Privacy Awareness Aug (\u2191)": 0.313, "Privacy Leakage RtA (\u2191)": 0.653, "Privacy Leakage TD (\u2193)": 0.060, "Privacy Leakage CD (\u2193)": 0.108, "Privacy Awareness Correlation (\u2191)": 0.170 }, { "Model": "Llama3-8b", "Privacy Awareness Normal (\u2191)": 0.332, "Privacy Awareness Aug (\u2191)": 0.996, "Privacy Leakage RtA (\u2191)": 0.660, "Privacy Leakage TD (\u2193)": 0.123, "Privacy Leakage CD (\u2193)": 0.190, "Privacy Awareness Correlation (\u2191)": 0.661 }, { "Model": "Llama3-70b", "Privacy Awareness Normal (\u2191)": 0.761, "Privacy Awareness Aug (\u2191)": 1.000, "Privacy Leakage RtA (\u2191)": 0.623, "Privacy Leakage TD (\u2193)": 0.155, "Privacy Leakage CD (\u2193)": 0.210, "Privacy Awareness Correlation (\u2191)": 0.566 }, { "Model": "GLM4", "Privacy Awareness Normal (\u2191)": 0.917, "Privacy Awareness Aug (\u2191)": 0.961, "Privacy Leakage RtA (\u2191)": 0.683, "Privacy Leakage TD (\u2193)": 0.131, "Privacy Leakage CD (\u2193)": 0.194, "Privacy Awareness Correlation (\u2191)": 0.416 }, { "Model": "Mixtral", "Privacy Awareness Normal (\u2191)": 0.721, "Privacy Awareness Aug (\u2191)": 0.986, "Privacy Leakage RtA (\u2191)": 0.698, "Privacy Leakage TD (\u2193)": 0.163, "Privacy Leakage CD (\u2193)": 0.290, "Privacy Awareness Correlation (\u2191)": 0.607 }]
truthfulness=[{"Model": "ChatGLM3", "Internal (\u2191)": 0.238, "External  (\u2191)": 0.674, "Hallucination  (\u2191)": 0.405, "Persona Sycophancy  (\u2193)": 0.031, "Preference Sycophancy  (\u2193)": 0.650, "Adv Factuality  (\u2191)": 0.139}, {"Model": "Llama3-8b", "Internal (\u2191)": 0.343, "External  (\u2191)": 0.731, "Hallucination  (\u2191)": 0.439, "Persona Sycophancy  (\u2193)": 0.026, "Preference Sycophancy  (\u2193)": 0.833, "Adv Factuality  (\u2191)": 0.598}, {"Model": "Llama3-70b", "Internal (\u2191)": 0.383, "External  (\u2191)": 0.752, "Hallucination  (\u2191)": 0.370, "Persona Sycophancy  (\u2193)": 0.033, "Preference Sycophancy  (\u2193)": 0.892, "Adv Factuality  (\u2191)": 0.962}, {"Model": "GLM4", "Internal (\u2191)": 0.391, "External  (\u2191)": 0.771, "Hallucination  (\u2191)": 0.389, "Persona Sycophancy  (\u2193)": 0.037, "Preference Sycophancy  (\u2193)": 0.692, "Adv Factuality  (\u2191)": 0.732}, {"Model": "Mixtral", "Internal (\u2191)": 0.396, "External  (\u2191)": 0.742, "Hallucination  (\u2191)": 0.453, "Persona Sycophancy  (\u2193)": 0.042, "Preference Sycophancy  (\u2193)": 0.242, "Adv Factuality  (\u2191)": 0.880}]
robustness = [{ "Model": "Baichuan-13b", "AdvGlue RS (\u2191)": 0.363, "AdvInstruction (\u2191)": 93.99, "OOD detection (\u2191)": 0.004, "OOD generalization (\u2191)": 0.539 }, { "Model": "ChatGLM2", "AdvGlue RS (\u2191)": 0.254, "AdvInstruction (\u2191)": 94.37, "OOD detection (\u2191)": 0.627, "OOD generalization (\u2191)": 0.778 }, { "Model": "Vicuna-13b", "AdvGlue RS (\u2191)": 0.18, "AdvInstruction (\u2191)": 96.01, "OOD detection (\u2191)": 0.635, "OOD generalization (\u2191)": 0.839 }, { "Model": "Vicuna-7b", "AdvGlue RS (\u2191)": 0.072, "AdvInstruction (\u2191)": 88.77, "OOD detection (\u2191)": 0.49, "OOD generalization (\u2191)": 0.753 }, { "Model": "Vicuna-33b", "AdvGlue RS (\u2191)": 0.219, "AdvInstruction (\u2191)": 95.97, "OOD detection (\u2191)": 0.685, "OOD generalization (\u2191)": 0.785 }, { "Model": "Llama2-7b", "AdvGlue RS (\u2191)": 0.374, "AdvInstruction (\u2191)": 96.68, "OOD detection (\u2191)": 0.465, "OOD generalization (\u2191)": 0.777 }, { "Model": "Llama2-13b", "AdvGlue RS (\u2191)": 0.306, "AdvInstruction (\u2191)": 96.48, "OOD detection (\u2191)": 0.432, "OOD generalization (\u2191)": 0.884 }, { "Model": "Koala-13b", "AdvGlue RS (\u2191)": 0.116, "AdvInstruction (\u2191)": 94.05, "OOD detection (\u2191)": 0.552, "OOD generalization (\u2191)": 0.584 }, { "Model": "Oasst-12b", "AdvGlue RS (\u2191)": 0.143, "AdvInstruction (\u2191)": 93.68, "OOD detection (\u2191)": 0.398, "OOD generalization (\u2191)": 0.883 }, { "Model": "Wizardlm-13b", "AdvGlue RS (\u2191)": 0.152, "AdvInstruction (\u2191)": 95.02, "OOD detection (\u2191)": 0.643, "OOD generalization (\u2191)": 0.871 }, { "Model": "ERNIE", "AdvGlue RS (\u2191)": 0.408, "AdvInstruction (\u2191)": 90.99, "OOD detection (\u2191)": 0.548, "OOD generalization (\u2191)": 0.795 }, { "Model": "ChatGPT", "AdvGlue RS (\u2191)": 0.326, "AdvInstruction (\u2191)": 97.42, "OOD detection (\u2191)": 0.697, "OOD generalization (\u2191)": 0.867 }, { "Model": "GPT-4", "AdvGlue RS (\u2191)": 0.591, "AdvInstruction (\u2191)": 96.36, "OOD detection (\u2191)": 0.805, "OOD generalization (\u2191)": 0.923 }, { "Model": "Llama2-70b", "AdvGlue RS (\u2191)": 0.471, "AdvInstruction (\u2191)": 97.64, "OOD detection (\u2191)": 0.461, "OOD generalization (\u2191)": 0.873 }, { "Model": "Mistral-7b", "AdvGlue RS (\u2191)": 0.331, "AdvInstruction (\u2191)": 95.76, "OOD detection (\u2191)": 0.407, "OOD generalization (\u2191)": 0.822 }, { "Model": "PaLM 2", "AdvGlue RS (\u2191)": 0.607, "AdvInstruction (\u2191)": 95.41, "OOD detection (\u2191)": 0.104, "OOD generalization (\u2191)": 0.822 }, { "Model": "ChatGLM3", "AdvGlue RS (\u2191)": 0.355, "AdvInstruction (\u2191)": 0.725, "OOD detection (\u2191)": 0.418, "OOD generalization (\u2191)": 0.565 }, { "Model": "Llama3-8b", "AdvGlue RS (\u2191)": 0.421, "AdvInstruction (\u2191)": 0.705, "OOD detection (\u2191)": 0.369, "OOD generalization (\u2191)": 0.830 }, { "Model": "Llama3-70b", "AdvGlue RS (\u2191)": 0.531, "AdvInstruction (\u2191)": 0.709, "OOD detection (\u2191)": 0.411, "OOD generalization (\u2191)": 0.760 }, { "Model": "GLM4", "AdvGlue RS (\u2191)": 0.580, "AdvInstruction (\u2191)": 0.709, "OOD detection (\u2191)": 0.792, "OOD generalization (\u2191)": 0.855 }, { "Model": "Mixtral", "AdvGlue RS (\u2191)": 0.558, "AdvInstruction (\u2191)": 0.703, "OOD detection (\u2191)": 0.593, "OOD generalization (\u2191)": 0.839 }]
ethics = [{ "Model": " GPT-4", "Social Chemistry 101 Acc  (\u2191)": 0.674, "ETHICS Acc  (\u2191)": 0.674, "MoralChoice Acc  (\u2191)": 1.0, "MoralChoice RtA  (\u2191)": 0.669, "Emotional Acc  (\u2191)": 0.945 }, { "Model": "PaLM 2", "Social Chemistry 101 Acc  (\u2191)": 0.67, "ETHICS Acc  (\u2191)": 0.602, "MoralChoice Acc  (\u2191)": 0.993, "MoralChoice RtA  (\u2191)": 0.429, "Emotional Acc  (\u2191)": 0.935 }, { "Model": "chatgpt", "Social Chemistry 101 Acc  (\u2191)": 0.654, "ETHICS Acc  (\u2191)": 0.668, "MoralChoice Acc  (\u2191)": 1.0, "MoralChoice RtA  (\u2191)": 0.682, "Emotional Acc  (\u2191)": 0.915 }, { "Model": "ernie", "Social Chemistry 101 Acc  (\u2191)": 0.651, "ETHICS Acc  (\u2191)": 0.601, "MoralChoice Acc  (\u2191)": 0.993, "MoralChoice RtA  (\u2191)": 0.953, "Emotional Acc  (\u2191)": 0.875 }, { "Model": "llama2-70b", "Social Chemistry 101 Acc  (\u2191)": 0.653, "ETHICS Acc  (\u2191)": 0.598, "MoralChoice Acc  (\u2191)": 0.991, "MoralChoice RtA  (\u2191)": 0.999, "Emotional Acc  (\u2191)": 0.875 }, { "Model": "wizardlm-13b", "Social Chemistry 101 Acc  (\u2191)": 0.652, "ETHICS Acc  (\u2191)": 0.655, "MoralChoice Acc  (\u2191)": 0.991, "MoralChoice RtA  (\u2191)": 0.85, "Emotional Acc  (\u2191)": 0.81 }, { "Model": "Mistral-7b", "Social Chemistry 101 Acc  (\u2191)": 0.647, "ETHICS Acc  (\u2191)": 0.66, "MoralChoice Acc  (\u2191)": 0.987, "MoralChoice RtA  (\u2191)": 0.86, "Emotional Acc  (\u2191)": 0.81 }, { "Model": "chatglm2", "Social Chemistry 101 Acc  (\u2191)": 0.588, "ETHICS Acc  (\u2191)": 0.613, "MoralChoice Acc  (\u2191)": 0.942, "MoralChoice RtA  (\u2191)": 0.651, "Emotional Acc  (\u2191)": 0.765 }, { "Model": "vicuna-13b", "Social Chemistry 101 Acc  (\u2191)": 0.518, "ETHICS Acc  (\u2191)": 0.633, "MoralChoice Acc  (\u2191)": 0.905, "MoralChoice RtA  (\u2191)": 0.99, "Emotional Acc  (\u2191)": 0.75 }, { "Model": "llama2-13b", "Social Chemistry 101 Acc  (\u2191)": 0.619, "ETHICS Acc  (\u2191)": 0.614, "MoralChoice Acc  (\u2191)": 0.962, "MoralChoice RtA  (\u2191)": 0.999, "Emotional Acc  (\u2191)": 0.735 }, { "Model": "vicuna-33b", "Social Chemistry 101 Acc  (\u2191)": 0.668, "ETHICS Acc  (\u2191)": 0.643, "MoralChoice Acc  (\u2191)": 0.985, "MoralChoice RtA  (\u2191)": 0.938, "Emotional Acc  (\u2191)": 0.725 }, { "Model": "baichuan-13b", "Social Chemistry 101 Acc  (\u2191)": 0.571, "ETHICS Acc  (\u2191)": 0.592, "MoralChoice Acc  (\u2191)": 0.789, "MoralChoice RtA  (\u2191)": 0.622, "Emotional Acc  (\u2191)": 0.705 }, { "Model": "llama2-7b", "Social Chemistry 101 Acc  (\u2191)": 0.609, "ETHICS Acc  (\u2191)": 0.657, "MoralChoice Acc  (\u2191)": 0.92, "MoralChoice RtA  (\u2191)": 0.999, "Emotional Acc  (\u2191)": 0.63 }, { "Model": "vicuna-7b", "Social Chemistry 101 Acc  (\u2191)": 0.594, "ETHICS Acc  (\u2191)": 0.609, "MoralChoice Acc  (\u2191)": 0.594, "MoralChoice RtA  (\u2191)": 0.944, "Emotional Acc  (\u2191)": 0.485 }, { "Model": "koala-13b", "Social Chemistry 101 Acc  (\u2191)": 0.546, "ETHICS Acc  (\u2191)": 0.465, "MoralChoice Acc  (\u2191)": 0.924, "MoralChoice RtA  (\u2191)": 0.872, "Emotional Acc  (\u2191)": 0.34 }, { "Model": "oasst-12b", "Social Chemistry 101 Acc  (\u2191)": 0.539, "ETHICS Acc  (\u2191)": 0.492, "MoralChoice Acc  (\u2191)": 0.505, "MoralChoice RtA  (\u2191)": 0.631, "Emotional Acc  (\u2191)": 0.105 }, { "Model": "ChatGLM3", "Social Chemistry 101 Acc (\u2191)": 0.640, "ETHICS Acc (\u2191)": 0.746, "MoralChoice Acc (\u2191)": 0.888, "MoralChoice RtA (\u2191)": 0.005, "Emotional Acc (\u2191)": 0.680 }, { "Model": "Llama3-8b", "Social Chemistry 101 Acc (\u2191)": 0.940, "ETHICS Acc (\u2191)": 0.645, "MoralChoice Acc (\u2191)": 0.969, "MoralChoice RtA (\u2191)": 0.969, "Emotional Acc (\u2191)": -1.000 }, { "Model": "Llama3-70b", "Social Chemistry 101 Acc (\u2191)": 0.891, "ETHICS Acc (\u2191)": 0.697, "MoralChoice Acc (\u2191)": 0.996, "MoralChoice RtA (\u2191)": 0.959, "Emotional Acc (\u2191)": -1.000 }, { "Model": "GLM4", "Social Chemistry 101 Acc (\u2191)": 0.687, "ETHICS Acc (\u2191)": 0.935, "MoralChoice Acc (\u2191)": 1.000, "MoralChoice RtA (\u2191)": 0.997, "Emotional Acc (\u2191)": 0.910 }, { "Model": "Mixtral", "Social Chemistry 101 Acc (\u2191)": 0.716, "ETHICS Acc (\u2191)": 0.941, "MoralChoice Acc (\u2191)": 1.000, "MoralChoice RtA (\u2191)": 0.993, "Emotional Acc (\u2191)": 0.910 }]
fairness=[{"Model": "ChatGLM3", "Stereotype Recognition  (\u2191)": 0.328, "Overall Agreement Rate  (\u2193)": 0.145, "Stereotype Query Test (\u2191)": 0.813, "Disparagement Sex (\u2191)": 0.313, "Disparagement Race (\u2191)": 0.277, "Prefereence RtA (\u2191)": -1.000}, {"Model": "Llama3-8b", "Stereotype Recognition  (\u2191)": 0.492, "Overall Agreement Rate  (\u2193)": 0.060, "Stereotype Query Test (\u2191)": 1.000, "Disparagement Sex (\u2191)": 0.087, "Disparagement Race (\u2191)": 0.552, "Prefereence RtA (\u2191)": 0.446}, {"Model": "Llama3-70b", "Stereotype Recognition  (\u2191)": 0.726, "Overall Agreement Rate  (\u2193)": 0.068, "Stereotype Query Test (\u2191)": 1.000, "Disparagement Sex (\u2191)": 0.000, "Disparagement Race (\u2191)": 0.008, "Prefereence RtA (\u2191)": 0.463}, {"Model": "GLM4", "Stereotype Recognition  (\u2191)": 0.612, "Overall Agreement Rate  (\u2193)": 0.060, "Stereotype Query Test (\u2191)": 1.000, "Disparagement Sex (\u2191)": 0.024, "Disparagement Race (\u2191)": 0.000, "Prefereence RtA (\u2191)": 0.529}, {"Model": "Mixtral", "Stereotype Recognition  (\u2191)": 0.569, "Overall Agreement Rate  (\u2193)": 0.040, "Stereotype Query Test (\u2191)": 1.000, "Disparagement Sex (\u2191)": 0.000, "Disparagement Race (\u2191)": 0.005, "Prefereence RtA (\u2191)": 0.833}]
safety=[{"Model": "ChatGLM3", "Jailbreak (\u2191)": 0.654, "Toxicity (\u2193)": -1.000, "Misuse (\u2191)": 0.137, "Exaggerated Safety (\u2193)": 0.865}, {"Model": "Llama3-8b", "Jailbreak (\u2191)": 0.928, "Toxicity (\u2193)": 0.059, "Misuse (\u2191)": 0.853, "Exaggerated Safety (\u2193)": 0.540}, {"Model": "Llama3-70b", "Jailbreak (\u2191)": 0.884, "Toxicity (\u2193)": 0.189, "Misuse (\u2191)": 0.847, "Exaggerated Safety (\u2193)": 0.485}, {"Model": "GLM4", "Jailbreak (\u2191)": 0.937, "Toxicity (\u2193)": -1.000, "Misuse (\u2191)": 0.894, "Exaggerated Safety (\u2193)": 0.503}, {"Model": "Mixtral", "Jailbreak (\u2191)": 0.821, "Toxicity (\u2193)": -1.000, "Misuse (\u2191)": 0.754, "Exaggerated Safety (\u2193)": 0.495}]