privacy = [{ "Model": "Baichuan-13b", "Privacy Awareness Normal (\u2191)": 0.082, "Privacy Awareness Aug (\u2191)": 0.225, "Privacy Leakage RtA (\u2191)": 0.65, "Privacy Leakage TD (\u2193)": 0.06, "Privacy Leakage CD (\u2193)": 0.11, "Privacy Awareness Correlation (\u2191)": 0.567 }, { "Model": "ChatGLM2", "Privacy Awareness Normal (\u2191)": 0.789, "Privacy Awareness Aug (\u2191)": 0.993, "Privacy Leakage RtA (\u2191)": 0.64, "Privacy Leakage TD (\u2193)": 0.13, "Privacy Leakage CD (\u2193)": 0.22, "Privacy Awareness Correlation (\u2191)": 0.248 }, { "Model": "ChatGPT", "Privacy Awareness Normal (\u2191)": 0.714, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.28, "Privacy Leakage TD (\u2193)": 0.3, "Privacy Leakage CD (\u2193)": 0.35, "Privacy Awareness Correlation (\u2191)": 0.665 }, { "Model": "ERNIE", "Privacy Awareness Normal (\u2191)": 0.911, "Privacy Awareness Aug (\u2191)": 0.993, "Privacy Leakage RtA (\u2191)": 0.89, "Privacy Leakage TD (\u2193)": 0.01, "Privacy Leakage CD (\u2193)": 0.02, "Privacy Awareness Correlation (\u2191)": 0.473 }, { "Model": "Koala-13b", "Privacy Awareness Normal (\u2191)": 0.718, "Privacy Awareness Aug (\u2191)": 0.982, "Privacy Leakage RtA (\u2191)": 0.27, "Privacy Leakage TD (\u2193)": 0.21, "Privacy Leakage CD (\u2193)": 0.32, "Privacy Awareness Correlation (\u2191)": 0.185 }, { "Model": "Llama2-7b", "Privacy Awareness Normal (\u2191)": 1.0, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.94, "Privacy Leakage TD (\u2193)": 0.02, "Privacy Leakage CD (\u2193)": 0.09, "Privacy Awareness Correlation (\u2191)": 0.101 }, { "Model": "Llama2-13b", "Privacy Awareness Normal (\u2191)": 1.0, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.98, "Privacy Leakage TD (\u2193)": 0.0, "Privacy Leakage CD (\u2193)": 0.03, "Privacy Awareness Correlation (\u2191)": 0.17 }, { "Model": "Oasst-12b", "Privacy Awareness Normal (\u2191)": 0.389, "Privacy Awareness Aug (\u2191)": 0.886, "Privacy Leakage RtA (\u2191)": 0.82, "Privacy Leakage TD (\u2193)": 0.01, "Privacy Leakage CD (\u2193)": 0.13, "Privacy Awareness Correlation (\u2191)": -0.161 }, { "Model": "Vicuna-7b", "Privacy Awareness Normal (\u2191)": 0.836, "Privacy Awareness Aug (\u2191)": 0.982, "Privacy Leakage RtA (\u2191)": 0.62, "Privacy Leakage TD (\u2193)": 0.17, "Privacy Leakage CD (\u2193)": 0.28, "Privacy Awareness Correlation (\u2191)": 0.373 }, { "Model": "Vicuna-13b", "Privacy Awareness Normal (\u2191)": 0.829, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.64, "Privacy Leakage TD (\u2193)": 0.21, "Privacy Leakage CD (\u2193)": 0.31, "Privacy Awareness Correlation (\u2191)": 0.367 }, { "Model": "Vicuna-33b", "Privacy Awareness Normal (\u2191)": 0.743, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.32, "Privacy Leakage TD (\u2193)": 0.28, "Privacy Leakage CD (\u2193)": 0.3, "Privacy Awareness Correlation (\u2191)": 0.442 }, { "Model": "Wizardlm-13b", "Privacy Awareness Normal (\u2191)": 0.979, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.87, "Privacy Leakage TD (\u2193)": 0.08, "Privacy Leakage CD (\u2193)": 0.35, "Privacy Awareness Correlation (\u2191)": 0.183 }, { "Model": "GPT-4", "Privacy Awareness Normal (\u2191)": 0.982, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.41, "Privacy Leakage TD (\u2193)": 0.33, "Privacy Leakage CD (\u2193)": 0.36, "Privacy Awareness Correlation (\u2191)": 0.634 }, { "Model": "Llama2-70b", "Privacy Awareness Normal (\u2191)": 1.0, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.86, "Privacy Leakage TD (\u2193)": 0.07, "Privacy Leakage CD (\u2193)": 0.22, "Privacy Awareness Correlation (\u2191)": 0.484 }, { "Model": "Mistral-7b", "Privacy Awareness Normal (\u2191)": 0.654, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.71, "Privacy Leakage TD (\u2193)": 0.04, "Privacy Leakage CD (\u2193)": 0.08, "Privacy Awareness Correlation (\u2191)": 0.469 }, { "Model": "PaLM 2", "Privacy Awareness Normal (\u2191)": 0.089, "Privacy Awareness Aug (\u2191)": 1.0, "Privacy Leakage RtA (\u2191)": 0.1, "Privacy Leakage TD (\u2193)": 0.26, "Privacy Leakage CD (\u2193)": 0.28, "Privacy Awareness Correlation (\u2191)": 0.572 }, { "Model": "ChatGLM3", "Privacy Awareness Normal (\u2191)": 0.034, "Privacy Awareness Aug (\u2191)": 0.313, "Privacy Leakage RtA (\u2191)": 0.653, "Privacy Leakage TD (\u2193)": 0.060, "Privacy Leakage CD (\u2193)": 0.108, "Privacy Awareness Correlation (\u2191)": 0.170 }, { "Model": "Llama3-8b", "Privacy Awareness Normal (\u2191)": 0.332, "Privacy Awareness Aug (\u2191)": 0.996, "Privacy Leakage RtA (\u2191)": 0.660, "Privacy Leakage TD (\u2193)": 0.123, "Privacy Leakage CD (\u2193)": 0.190, "Privacy Awareness Correlation (\u2191)": 0.661 }, { "Model": "Llama3-70b", "Privacy Awareness Normal (\u2191)": 0.761, "Privacy Awareness Aug (\u2191)": 1.000, "Privacy Leakage RtA (\u2191)": 0.623, "Privacy Leakage TD (\u2193)": 0.155, "Privacy Leakage CD (\u2193)": 0.210, "Privacy Awareness Correlation (\u2191)": 0.566 }, { "Model": "GLM4", "Privacy Awareness Normal (\u2191)": 0.917, "Privacy Awareness Aug (\u2191)": 0.961, "Privacy Leakage RtA (\u2191)": 0.683, "Privacy Leakage TD (\u2193)": 0.131, "Privacy Leakage CD (\u2193)": 0.194, "Privacy Awareness Correlation (\u2191)": 0.416 }, { "Model": "Mixtral", "Privacy Awareness Normal (\u2191)": 0.721, "Privacy Awareness Aug (\u2191)": 0.986, "Privacy Leakage RtA (\u2191)": 0.698, "Privacy Leakage TD (\u2193)": 0.163, "Privacy Leakage CD (\u2193)": 0.290, "Privacy Awareness Correlation (\u2191)": 0.607 }]
robustness = [{ "Model": "Baichuan-13b", "AdvGlue RS (\u2191)": 0.363, "AdvInstruction (\u2191)": 93.99, "OOD detection (\u2191)": 0.004, "OOD generalization (\u2191)": 0.539 }, { "Model": "ChatGLM2", "AdvGlue RS (\u2191)": 0.254, "AdvInstruction (\u2191)": 94.37, "OOD detection (\u2191)": 0.627, "OOD generalization (\u2191)": 0.778 }, { "Model": "Vicuna-13b", "AdvGlue RS (\u2191)": 0.18, "AdvInstruction (\u2191)": 96.01, "OOD detection (\u2191)": 0.635, "OOD generalization (\u2191)": 0.839 }, { "Model": "Vicuna-7b", "AdvGlue RS (\u2191)": 0.072, "AdvInstruction (\u2191)": 88.77, "OOD detection (\u2191)": 0.49, "OOD generalization (\u2191)": 0.753 }, { "Model": "Vicuna-33b", "AdvGlue RS (\u2191)": 0.219, "AdvInstruction (\u2191)": 95.97, "OOD detection (\u2191)": 0.685, "OOD generalization (\u2191)": 0.785 }, { "Model": "Llama2-7b", "AdvGlue RS (\u2191)": 0.374, "AdvInstruction (\u2191)": 96.68, "OOD detection (\u2191)": 0.465, "OOD generalization (\u2191)": 0.777 }, { "Model": "Llama2-13b", "AdvGlue RS (\u2191)": 0.306, "AdvInstruction (\u2191)": 96.48, "OOD detection (\u2191)": 0.432, "OOD generalization (\u2191)": 0.884 }, { "Model": "Koala-13b", "AdvGlue RS (\u2191)": 0.116, "AdvInstruction (\u2191)": 94.05, "OOD detection (\u2191)": 0.552, "OOD generalization (\u2191)": 0.584 }, { "Model": "Oasst-12b", "AdvGlue RS (\u2191)": 0.143, "AdvInstruction (\u2191)": 93.68, "OOD detection (\u2191)": 0.398, "OOD generalization (\u2191)": 0.883 }, { "Model": "Wizardlm-13b", "AdvGlue RS (\u2191)": 0.152, "AdvInstruction (\u2191)": 95.02, "OOD detection (\u2191)": 0.643, "OOD generalization (\u2191)": 0.871 }, { "Model": "ERNIE", "AdvGlue RS (\u2191)": 0.408, "AdvInstruction (\u2191)": 90.99, "OOD detection (\u2191)": 0.548, "OOD generalization (\u2191)": 0.795 }, { "Model": "ChatGPT", "AdvGlue RS (\u2191)": 0.326, "AdvInstruction (\u2191)": 97.42, "OOD detection (\u2191)": 0.697, "OOD generalization (\u2191)": 0.867 }, { "Model": "GPT-4", "AdvGlue RS (\u2191)": 0.591, "AdvInstruction (\u2191)": 96.36, "OOD detection (\u2191)": 0.805, "OOD generalization (\u2191)": 0.923 }, { "Model": "Llama2-70b", "AdvGlue RS (\u2191)": 0.471, "AdvInstruction (\u2191)": 97.64, "OOD detection (\u2191)": 0.461, "OOD generalization (\u2191)": 0.873 }, { "Model": "Mistral-7b", "AdvGlue RS (\u2191)": 0.331, "AdvInstruction (\u2191)": 95.76, "OOD detection (\u2191)": 0.407, "OOD generalization (\u2191)": 0.822 }, { "Model": "PaLM 2", "AdvGlue RS (\u2191)": 0.607, "AdvInstruction (\u2191)": 95.41, "OOD detection (\u2191)": 0.104, "OOD generalization (\u2191)": 0.822 }, { "Model": "ChatGLM3", "AdvGlue RS (\u2191)": 0.355, "AdvInstruction (\u2191)": 0.725, "OOD detection (\u2191)": 0.418, "OOD generalization (\u2191)": 0.565 }, { "Model": "Llama3-8b", "AdvGlue RS (\u2191)": 0.421, "AdvInstruction (\u2191)": 0.705, "OOD detection (\u2191)": 0.369, "OOD generalization (\u2191)": 0.830 }, { "Model": "Llama3-70b", "AdvGlue RS (\u2191)": 0.531, "AdvInstruction (\u2191)": 0.709, "OOD detection (\u2191)": 0.411, "OOD generalization (\u2191)": 0.760 }, { "Model": "GLM4", "AdvGlue RS (\u2191)": 0.580, "AdvInstruction (\u2191)": 0.709, "OOD detection (\u2191)": 0.792, "OOD generalization (\u2191)": 0.855 }, { "Model": "Mixtral", "AdvGlue RS (\u2191)": 0.558, "AdvInstruction (\u2191)": 0.703, "OOD detection (\u2191)": 0.593, "OOD generalization (\u2191)": 0.839 }]
ethics = [{ "Model": " GPT-4", "Social Chemistry 101 Acc  (\u2191)": 0.674, "ETHICS Acc  (\u2191)": 0.674, "MoralChoice Acc  (\u2191)": 1.0, "MoralChoice RtA  (\u2191)": 0.669, "Emotional Acc  (\u2191)": 0.945 }, { "Model": "PaLM 2", "Social Chemistry 101 Acc  (\u2191)": 0.67, "ETHICS Acc  (\u2191)": 0.602, "MoralChoice Acc  (\u2191)": 0.993, "MoralChoice RtA  (\u2191)": 0.429, "Emotional Acc  (\u2191)": 0.935 }, { "Model": "chatgpt", "Social Chemistry 101 Acc  (\u2191)": 0.654, "ETHICS Acc  (\u2191)": 0.668, "MoralChoice Acc  (\u2191)": 1.0, "MoralChoice RtA  (\u2191)": 0.682, "Emotional Acc  (\u2191)": 0.915 }, { "Model": "ernie", "Social Chemistry 101 Acc  (\u2191)": 0.651, "ETHICS Acc  (\u2191)": 0.601, "MoralChoice Acc  (\u2191)": 0.993, "MoralChoice RtA  (\u2191)": 0.953, "Emotional Acc  (\u2191)": 0.875 }, { "Model": "llama2-70b", "Social Chemistry 101 Acc  (\u2191)": 0.653, "ETHICS Acc  (\u2191)": 0.598, "MoralChoice Acc  (\u2191)": 0.991, "MoralChoice RtA  (\u2191)": 0.999, "Emotional Acc  (\u2191)": 0.875 }, { "Model": "wizardlm-13b", "Social Chemistry 101 Acc  (\u2191)": 0.652, "ETHICS Acc  (\u2191)": 0.655, "MoralChoice Acc  (\u2191)": 0.991, "MoralChoice RtA  (\u2191)": 0.85, "Emotional Acc  (\u2191)": 0.81 }, { "Model": "Mistral-7b", "Social Chemistry 101 Acc  (\u2191)": 0.647, "ETHICS Acc  (\u2191)": 0.66, "MoralChoice Acc  (\u2191)": 0.987, "MoralChoice RtA  (\u2191)": 0.86, "Emotional Acc  (\u2191)": 0.81 }, { "Model": "chatglm2", "Social Chemistry 101 Acc  (\u2191)": 0.588, "ETHICS Acc  (\u2191)": 0.613, "MoralChoice Acc  (\u2191)": 0.942, "MoralChoice RtA  (\u2191)": 0.651, "Emotional Acc  (\u2191)": 0.765 }, { "Model": "vicuna-13b", "Social Chemistry 101 Acc  (\u2191)": 0.518, "ETHICS Acc  (\u2191)": 0.633, "MoralChoice Acc  (\u2191)": 0.905, "MoralChoice RtA  (\u2191)": 0.99, "Emotional Acc  (\u2191)": 0.75 }, { "Model": "llama2-13b", "Social Chemistry 101 Acc  (\u2191)": 0.619, "ETHICS Acc  (\u2191)": 0.614, "MoralChoice Acc  (\u2191)": 0.962, "MoralChoice RtA  (\u2191)": 0.999, "Emotional Acc  (\u2191)": 0.735 }, { "Model": "vicuna-33b", "Social Chemistry 101 Acc  (\u2191)": 0.668, "ETHICS Acc  (\u2191)": 0.643, "MoralChoice Acc  (\u2191)": 0.985, "MoralChoice RtA  (\u2191)": 0.938, "Emotional Acc  (\u2191)": 0.725 }, { "Model": "baichuan-13b", "Social Chemistry 101 Acc  (\u2191)": 0.571, "ETHICS Acc  (\u2191)": 0.592, "MoralChoice Acc  (\u2191)": 0.789, "MoralChoice RtA  (\u2191)": 0.622, "Emotional Acc  (\u2191)": 0.705 }, { "Model": "llama2-7b", "Social Chemistry 101 Acc  (\u2191)": 0.609, "ETHICS Acc  (\u2191)": 0.657, "MoralChoice Acc  (\u2191)": 0.92, "MoralChoice RtA  (\u2191)": 0.999, "Emotional Acc  (\u2191)": 0.63 }, { "Model": "vicuna-7b", "Social Chemistry 101 Acc  (\u2191)": 0.594, "ETHICS Acc  (\u2191)": 0.609, "MoralChoice Acc  (\u2191)": 0.594, "MoralChoice RtA  (\u2191)": 0.944, "Emotional Acc  (\u2191)": 0.485 }, { "Model": "koala-13b", "Social Chemistry 101 Acc  (\u2191)": 0.546, "ETHICS Acc  (\u2191)": 0.465, "MoralChoice Acc  (\u2191)": 0.924, "MoralChoice RtA  (\u2191)": 0.872, "Emotional Acc  (\u2191)": 0.34 }, { "Model": "oasst-12b", "Social Chemistry 101 Acc  (\u2191)": 0.539, "ETHICS Acc  (\u2191)": 0.492, "MoralChoice Acc  (\u2191)": 0.505, "MoralChoice RtA  (\u2191)": 0.631, "Emotional Acc  (\u2191)": 0.105 }, { "Model": "ChatGLM3", "Social Chemistry 101 Acc (\u2191)": 0.640, "ETHICS Acc (\u2191)": 0.746, "MoralChoice Acc (\u2191)": 0.888, "MoralChoice RtA (\u2191)": 0.005, "Emotional Acc (\u2191)": 0.680 }, { "Model": "Llama3-8b", "Social Chemistry 101 Acc (\u2191)": 0.940, "ETHICS Acc (\u2191)": 0.645, "MoralChoice Acc (\u2191)": 0.969, "MoralChoice RtA (\u2191)": 0.969, "Emotional Acc (\u2191)": -1.000 }, { "Model": "Llama3-70b", "Social Chemistry 101 Acc (\u2191)": 0.891, "ETHICS Acc (\u2191)": 0.697, "MoralChoice Acc (\u2191)": 0.996, "MoralChoice RtA (\u2191)": 0.959, "Emotional Acc (\u2191)": -1.000 }, { "Model": "GLM4", "Social Chemistry 101 Acc (\u2191)": 0.687, "ETHICS Acc (\u2191)": 0.935, "MoralChoice Acc (\u2191)": 1.000, "MoralChoice RtA (\u2191)": 0.997, "Emotional Acc (\u2191)": 0.910 }, { "Model": "Mixtral", "Social Chemistry 101 Acc (\u2191)": 0.716, "ETHICS Acc (\u2191)": 0.941, "MoralChoice Acc (\u2191)": 1.000, "MoralChoice RtA (\u2191)": 0.993, "Emotional Acc (\u2191)": 0.910 }]
truthfulness=[{"Model": "ChatGPT", "Internal (\u2191)": 0.288, "External  (\u2191)": 0.726, "Hallucination  (\u2191)": 0.529, "Persona Sycophancy  (\u2193)": 0.039, "Preference Sycophancy  (\u2193)": 0.257, "Adv Factuality  (\u2191)": 0.708}, {"Model": "GPT-4", "Internal (\u2191) ": 0.417, "External  (\u2191)": 0.793, "Hallucination  (\u2191)": 0.516, "Persona Sycophancy  (\u2193)": 0.029, "Preference Sycophancy  (\u2193)": 0.296, "Adv Factuality  (\u2191)": 0.813}, {"Model": "ChatGLM2", "Internal (\u2191) ": 0.127, "External  (\u2191)": 0.542, "Hallucination  (\u2191)": 0.542, "Persona Sycophancy  (\u2193)": 0.036, "Preference Sycophancy  (\u2193)": 0.432, "Adv Factuality  (\u2191)": 0.349}, {"Model": "Vicuna-33b", "Internal (\u2191) ": 0.261, "External  (\u2191)": 0.726, "Hallucination  (\u2191)": 0.423, "Persona Sycophancy  (\u2193)": 0.038, "Preference Sycophancy  (\u2193)": 0.458, "Adv Factuality  (\u2191)": 0.699}, {"Model": "Vicuna-13b", "Internal (\u2191) ": 0.18, "External  (\u2191)": 0.623, "Hallucination  (\u2191)": 0.403, "Persona Sycophancy  (\u2193)": 0.036, "Preference Sycophancy  (\u2193)": 0.375, "Adv Factuality  (\u2191)": 0.665}, {"Model": "Vicuna-7b", "Internal (\u2191) ": 0.132, "External  (\u2191)": 0.581, "Hallucination  (\u2191)": 0.347, "Persona Sycophancy  (\u2193)": 0.03, "Preference Sycophancy  (\u2193)": 0.395, "Adv Factuality  (\u2191)": 0.469}, {"Model": "Llama2-70b", "Internal (\u2191) ": 0.313, "External  (\u2191)": 0.721, "Hallucination  (\u2191)": 0.402, "Persona Sycophancy  (\u2193)": 0.043, "Preference Sycophancy  (\u2193)": 0.468, "Adv Factuality  (\u2191)": 0.794}, {"Model": "Llama2-13b", "Internal (\u2191) ": 0.235, "External  (\u2191)": 0.722, "Hallucination  (\u2191)": 0.404, "Persona Sycophancy  (\u2193)": 0.032, "Preference Sycophancy  (\u2193)": 0.571, "Adv Factuality  (\u2191)": 0.78}, {"Model": "Llama2-7b", "Internal (\u2191) ": 0.203, "External  (\u2191)": 0.638, "Hallucination  (\u2191)": 0.396, "Persona Sycophancy  (\u2193)": 0.035, "Preference Sycophancy  (\u2193)": 0.587, "Adv Factuality  (\u2191)": 0.718}, {"Model": "Wizardlm-13b", "Internal (\u2191) ": 0.19, "External  (\u2191)": 0.574, "Hallucination  (\u2191)": 0.356, "Persona Sycophancy  (\u2193)": 0.025, "Preference Sycophancy  (\u2193)": 0.385, "Adv Factuality  (\u2191)": 0.794}, {"Model": "Koala-13b", "Internal (\u2191) ": 0.145, "External  (\u2191)": 0.553, "Hallucination  (\u2191)": 0.451, "Persona Sycophancy  (\u2193)": 0.04, "Preference Sycophancy  (\u2193)": 0.5, "Adv Factuality  (\u2191)": 0.435}, {"Model": "Baichuan-13b", "Internal (\u2191) ": 0.17, "External  (\u2191)": 0.622, "Hallucination  (\u2191)": 0.306, "Persona Sycophancy  (\u2193)": 0.032, "Preference Sycophancy  (\u2193)": 0.286, "Adv Factuality  (\u2191)": 0.44}, {"Model": "Oasst-12b", "Internal (\u2191) ": 0.101, "External  (\u2191)": 0.534, "Hallucination  (\u2191)": 0.418, "Persona Sycophancy  (\u2193)": 0.031, "Preference Sycophancy  (\u2193)": 0.436, "Adv Factuality  (\u2191)": 0.221}, {"Model": "ERNIE", "Internal (\u2191) ": 0.255, "External  (\u2191)": 0.689, "Hallucination  (\u2191)": 0.515, "Persona Sycophancy  (\u2193)": 0.019, "Preference Sycophancy  (\u2193)": 0.312, "Adv Factuality  (\u2191)": 0.407}, {"Model": "Mistral-7b", "Internal (\u2191) ": 0.341, "External  (\u2191)": 0.687, "Hallucination  (\u2191)": 0.458, "Persona Sycophancy  (\u2193)": 0.035, "Preference Sycophancy  (\u2193)": 0.293, "Adv Factuality  (\u2191)": 0.426}, {"Model": "PaLM2", "Internal (\u2191) ": 0.284, "External  (\u2191)": 0.532, "Hallucination  (\u2191)": 0.379, "Persona Sycophancy  (\u2193)": 0.028, "Preference Sycophancy  (\u2193)": 0.581, "Adv Factuality  (\u2191)": 0.273}, {"Model": "ChatGLM3", "Internal (\u2191)": 0.238, "External  (\u2191)": 0.674, "Hallucination  (\u2191)": 0.405, "Persona Sycophancy  (\u2193)": 0.031, "Preference Sycophancy  (\u2193)": 0.650, "Adv Factuality  (\u2191)": 0.139}, {"Model": "Llama3-8b", "Internal (\u2191)": 0.343, "External  (\u2191)": 0.731, "Hallucination  (\u2191)": 0.439, "Persona Sycophancy  (\u2193)": 0.026, "Preference Sycophancy  (\u2193)": 0.833, "Adv Factuality  (\u2191)": 0.598}, {"Model": "Llama3-70b", "Internal (\u2191)": 0.383, "External  (\u2191)": 0.752, "Hallucination  (\u2191)": 0.370, "Persona Sycophancy  (\u2193)": 0.033, "Preference Sycophancy  (\u2193)": 0.892, "Adv Factuality  (\u2191)": 0.962}, {"Model": "GLM4", "Internal (\u2191)": 0.391, "External  (\u2191)": 0.771, "Hallucination  (\u2191)": 0.389, "Persona Sycophancy  (\u2193)": 0.037, "Preference Sycophancy  (\u2193)": 0.692, "Adv Factuality  (\u2191)": 0.732}, {"Model": "Mixtral", "Internal (\u2191)": 0.396, "External  (\u2191)": 0.742, "Hallucination  (\u2191)": 0.453, "Persona Sycophancy  (\u2193)": 0.042, "Preference Sycophancy  (\u2193)": 0.242, "Adv Factuality  (\u2191)": 0.880}]
fairness=[{"Model": "baichuan-13b", "Stereotype Recognition  (\u2191)": 0.388, "Overall Agreement Rate  (\u2193)": 0.279, "Stereotype Query Test (\u2191)": 0.063, "Disparagement Sex (\u2191)": 0.183, "Disparagement Race (\u2191)": 0.001, "Prefereence RtA (\u2191)": 0.021}, {"Model": "chatglm2", "Stereotype Recognition  (\u2191)": 0.391, "Overall Agreement Rate  (\u2193)": 0.594, "Stereotype Query Test (\u2191)": 0.989, "Disparagement Sex (\u2191)": 0.037, "Disparagement Race (\u2191)": 0.0, "Prefereence RtA (\u2191)": 0.579}, {"Model": "chatgpt", "Stereotype Recognition  (\u2191)": 0.608, "Overall Agreement Rate  (\u2193)": 0.12, "Stereotype Query Test (\u2191)": 1.0, "Disparagement Sex (\u2191)": 0.001, "Disparagement Race (\u2191)": 0.136, "Prefereence RtA (\u2191)": 0.425}, {"Model": "ernie", "Stereotype Recognition  (\u2191)": 0.457, "Overall Agreement Rate  (\u2193)": 0.018, "Stereotype Query Test (\u2191)": 0.926, "Disparagement Sex (\u2191)": 0.0, "Disparagement Race (\u2191)": 0.002, "Prefereence RtA (\u2191)": 0.904}, {"Model": "gpt-4", "Stereotype Recognition  (\u2191)": 0.656, "Overall Agreement Rate  (\u2193)": 0.018, "Stereotype Query Test (\u2191)": 1.0, "Disparagement Sex (\u2191)": 0.006, "Disparagement Race (\u2191)": 0.173, "Prefereence RtA (\u2191)": 0.525}, {"Model": "koala-13b", "Stereotype Recognition  (\u2191)": 0.386, "Overall Agreement Rate  (\u2193)": 0.402, "Stereotype Query Test (\u2191)": 1.0, "Disparagement Sex (\u2191)": 0.171, "Disparagement Race (\u2191)": 0.036, "Prefereence RtA (\u2191)": 0.354}, {"Model": "llama2-13b", "Stereotype Recognition  (\u2191)": 0.429, "Overall Agreement Rate  (\u2193)": 0.005, "Stereotype Query Test (\u2191)": 1.0, "Disparagement Sex (\u2191)": 0.0, "Disparagement Race (\u2191)": 0.095, "Prefereence RtA (\u2191)": 0.458}, {"Model": "llama2-70b", "Stereotype Recognition  (\u2191)": 0.616, "Overall Agreement Rate  (\u2193)": 0.084, "Stereotype Query Test (\u2191)": 1.0, "Disparagement Sex (\u2191)": 0.006, "Disparagement Race (\u2191)": 0.01, "Prefereence RtA (\u2191)": 0.513}, {"Model": "llama2-7b", "Stereotype Recognition  (\u2191)": 0.405, "Overall Agreement Rate  (\u2193)": 0.027, "Stereotype Query Test (\u2191)": 1.0, "Disparagement Sex (\u2191)": 0.103, "Disparagement Race (\u2191)": 0.0, "Prefereence RtA (\u2191)": 0.575}, {"Model": "oasst-12b", "Stereotype Recognition  (\u2191)": 0.327, "Overall Agreement Rate  (\u2193)": 0.722, "Stereotype Query Test (\u2191)": 0.958, "Disparagement Sex (\u2191)": 0.64, "Disparagement Race (\u2191)": 0.98, "Prefereence RtA (\u2191)": 0.4}, {"Model": "vicuna-13b", "Stereotype Recognition  (\u2191)": 0.404, "Overall Agreement Rate  (\u2193)": 0.095, "Stereotype Query Test (\u2191)": 1.0, "Disparagement Sex (\u2191)": 0.002, "Disparagement Race (\u2191)": 0.873, "Prefereence RtA (\u2191)": 0.517}, {"Model": "vicuna-33b", "Stereotype Recognition  (\u2191)": 0.505, "Overall Agreement Rate  (\u2193)": 0.399, "Stereotype Query Test (\u2191)": 1.0, "Disparagement Sex (\u2191)": 0.006, "Disparagement Race (\u2191)": 0.793, "Prefereence RtA (\u2191)": 0.413}, {"Model": "vicuna-7b", "Stereotype Recognition  (\u2191)": 0.409, "Overall Agreement Rate  (\u2193)": 0.265, "Stereotype Query Test (\u2191)": 0.937, "Disparagement Sex (\u2191)": 0.431, "Disparagement Race (\u2191)": 0.352, "Prefereence RtA (\u2191)": 0.408}, {"Model": "wizardlm-13b", "Stereotype Recognition  (\u2191)": 0.459, "Overall Agreement Rate  (\u2193)": 0.201, "Stereotype Query Test (\u2191)": 1.0, "Disparagement Sex (\u2191)": 0.017, "Disparagement Race (\u2191)": 0.486, "Prefereence RtA (\u2191)": 0.479}, {"Model": "Mistral-7b", "Stereotype Recognition  (\u2191)": 0.473, "Overall Agreement Rate  (\u2193)": 0.086, "Stereotype Query Test (\u2191)": 0.979, "Disparagement Sex (\u2191)": 0.325, "Disparagement Race (\u2191)": 0.749, "Prefereence RtA (\u2191)": 0.442}, {"Model": "PaLM2", "Stereotype Recognition  (\u2191)": 0.634, "Overall Agreement Rate  (\u2193)": 0.075, "Stereotype Query Test (\u2191)": 0.947, "Disparagement Sex (\u2191)": 0.33, "Disparagement Race (\u2191)": 0.0, "Prefereence RtA (\u2191)": 0.365}, {"Model": "ChatGLM3", "Stereotype Recognition  (\u2191)": 0.328, "Overall Agreement Rate  (\u2193)": 0.145, "Stereotype Query Test (\u2191)": 0.813, "Disparagement Sex (\u2191)": 0.313, "Disparagement Race (\u2191)": 0.277, "Prefereence RtA (\u2191)": -1.000}, {"Model": "Llama3-8b", "Stereotype Recognition  (\u2191)": 0.492, "Overall Agreement Rate  (\u2193)": 0.060, "Stereotype Query Test (\u2191)": 1.000, "Disparagement Sex (\u2191)": 0.087, "Disparagement Race (\u2191)": 0.552, "Prefereence RtA (\u2191)": 0.446}, {"Model": "Llama3-70b", "Stereotype Recognition  (\u2191)": 0.726, "Overall Agreement Rate  (\u2193)": 0.068, "Stereotype Query Test (\u2191)": 1.000, "Disparagement Sex (\u2191)": 0.000, "Disparagement Race (\u2191)": 0.008, "Prefereence RtA (\u2191)": 0.463}, {"Model": "GLM4", "Stereotype Recognition  (\u2191)": 0.612, "Overall Agreement Rate  (\u2193)": 0.060, "Stereotype Query Test (\u2191)": 1.000, "Disparagement Sex (\u2191)": 0.024, "Disparagement Race (\u2191)": 0.000, "Prefereence RtA (\u2191)": 0.529}, {"Model": "Mixtral", "Stereotype Recognition  (\u2191)": 0.569, "Overall Agreement Rate  (\u2193)": 0.040, "Stereotype Query Test (\u2191)": 1.000, "Disparagement Sex (\u2191)": 0.000, "Disparagement Race (\u2191)": 0.005, "Prefereence RtA (\u2191)": 0.833}]
safety=[{"Model": "Llama2-13b", "Jailbreak (\u2191)": 0.959, "Toxicity (\u2193)": 0.205, "Misuse (\u2191)": 0.963, "Exaggerated Safety (\u2193)": 0.55}, {"Model": "Llama2-70b", "Jailbreak (\u2191)": 0.974, "Toxicity (\u2193)": 0.248, "Misuse (\u2191)": 0.956, "Exaggerated Safety (\u2193)": 0.315}, {"Model": "Llama2-7b", "Jailbreak (\u2191)": 0.945, "Toxicity (\u2193)": 0.191, "Misuse (\u2191)": 0.943, "Exaggerated Safety (\u2193)": 0.49}, {"Model": "GPT-4", "Jailbreak (\u2191)": 0.914, "Toxicity (\u2193)": 0.386, "Misuse (\u2191)": 0.924, "Exaggerated Safety (\u2193)": 0.085}, {"Model": "ChatGPT", "Jailbreak (\u2191)": 0.898, "Toxicity (\u2193)": 0.352, "Misuse (\u2191)": 0.91, "Exaggerated Safety (\u2193)": 0.15}, {"Model": "ERNIE", "Jailbreak (\u2191)": 0.949, "Toxicity (\u2193)": 0.072, "Misuse (\u2191)": 0.899, "Exaggerated Safety (\u2193)": 0.385}, {"Model": "Wizardlm-13b", "Jailbreak (\u2191)": 0.865, "Toxicity (\u2193)": 0.183, "Misuse (\u2191)": 0.883, "Exaggerated Safety (\u2193)": 0.06}, {"Model": "Vicuna-13b", "Jailbreak (\u2191)": 0.781, "Toxicity (\u2193)": 0.374, "Misuse (\u2191)": 0.848, "Exaggerated Safety (\u2193)": 0.095}, {"Model": "ChatGLM2", "Jailbreak (\u2191)": 0.845, "Toxicity (\u2193)": 0.141, "Misuse (\u2191)": 0.819, "Exaggerated Safety (\u2193)": 0.15}, {"Model": "Koala-13b", "Jailbreak (\u2191)": 0.691, "Toxicity (\u2193)": 0.237, "Misuse (\u2191)": 0.738, "Exaggerated Safety (\u2193)": 0.045}, {"Model": "Vicuna-33b", "Jailbreak (\u2191)": 0.585, "Toxicity (\u2193)": 0.294, "Misuse (\u2191)": 0.735, "Exaggerated Safety (\u2193)": 0.035}, {"Model": "Mistral-7b", "Jailbreak (\u2191)": 0.59, "Toxicity (\u2193)": 0.262, "Misuse (\u2191)": 0.709, "Exaggerated Safety (\u2193)": 0.46}, {"Model": "Oasst-12b", "Jailbreak (\u2191)": 0.69, "Toxicity (\u2193)": 0.154, "Misuse (\u2191)": 0.583, "Exaggerated Safety (\u2193)": 0.05}, {"Model": "Vicuna-7b", "Jailbreak (\u2191)": 0.596, "Toxicity (\u2193)": 0.213, "Misuse (\u2191)": 0.565, "Exaggerated Safety (\u2193)": 0.09}, {"Model": "PaLM 2", "Jailbreak (\u2191)": 0.486, "Toxicity (\u2193)": 0.317, "Misuse (\u2191)": 0.473, "Exaggerated Safety (\u2193)": 0.377}, {"Model": "Baichuan-13b", "Jailbreak (\u2191)": 0.25, "Toxicity (\u2193)": 0.112, "Misuse (\u2191)": 0.114, "Exaggerated Safety (\u2193)": 0.19}, {"Model": "ChatGLM3", "Jailbreak (\u2191)": 0.654, "Toxicity (\u2193)": -1.000, "Misuse (\u2191)": 0.137, "Exaggerated Safety (\u2193)": 0.865}, {"Model": "Llama3-8b", "Jailbreak (\u2191)": 0.928, "Toxicity (\u2193)": 0.059, "Misuse (\u2191)": 0.853, "Exaggerated Safety (\u2193)": 0.540}, {"Model": "Llama3-70b", "Jailbreak (\u2191)": 0.884, "Toxicity (\u2193)": 0.189, "Misuse (\u2191)": 0.847, "Exaggerated Safety (\u2193)": 0.485}, {"Model": "GLM4", "Jailbreak (\u2191)": 0.937, "Toxicity (\u2193)": -1.000, "Misuse (\u2191)": 0.894, "Exaggerated Safety (\u2193)": 0.503}, {"Model": "Mixtral", "Jailbreak (\u2191)": 0.821, "Toxicity (\u2193)": -1.000, "Misuse (\u2191)": 0.754, "Exaggerated Safety (\u2193)": 0.495}]