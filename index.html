<!doctype html>
<html>

<head>
  <title>TrustLLM-Benchmark</title>
  <link rel="icon" href="img/logo_only.png" type="image/icon type">
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" media="screen" rel="stylesheet" type="text/css" />
  <!-- <script src="https://cdn.tailwindcss.com"></script> -->
  <link href="/dist/output.css" rel="stylesheet">
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <script src="js/footer.js"></script>
  <script src="js/index.js"></script>

  <style>

  </style>
</head>





<body>

  <div class="menu-container"></div>
  <div class="container">
    <img src="img/logo.png" class="title-icon">
  </div>

  <div class="banner">
    <div class="banner-table flex-column">
      <div class="flex-row">
        <div class="flex-item flex-column">
          <h3 class="add-top-margin-small">TrustLLM: Trustworthiness in Large Language Models</h3>
        </div>
      </div>
    </div>
  </div>



  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">

        <h1 class="supportTitle">Introduction</h1>
        <br>
        <hr>
        <div class="arch">
          <img src="img/benchmark_arch_00.png" class="title-icon2" alt="Rank Card">
        </div>

<!--        <div class="flex-row">-->
<!--          <div class="flex-item flex-item-stretch-4 flex-column">-->
<!--            <p class="text">-->
<!--              <a class="highlight-text">Goals</a><br>-->
<!--              In the context of trustworthy LLMs, our objectives are multifaceted. First, we want to define what makes-->
<!--              an LLM trustworthy and set clear guidelines for this research area. This means selecting the right data,-->
<!--              tasks, and ways to measure an LLM's trustworthiness. Secondly, we intend to evaluate the performance of-->
<!--              existing mainstream LLMs across various aspects related to trustworthiness. Lastly, we aspire to gain new-->
<!--              insights from these evaluations that could promote progress in future research.-->
<!--            </p>-->
<!--          </div>-->
<!--        </div>-->


        <div class="flex-row">
          <div class="flex-item flex-item-stretch-4 flex-column">
            <p class="text">

              In this work, we introduce TrustLLM which thoroughly explores the trustworthiness of LLMs. Specifically, there are three-fold major contributions of TrustLLM:
              (1) Firstly, we have proposed a set of guidelines based on a wide range of literature reviews for evaluating the trustworthiness of LLMs, which is a taxonomy encompassing eight aspects, including truthfulness, safety, fairness, robustness, privacy, machine ethics, transparency, and accountability.
              (2) Secondly, we have established a benchmark for six of these aspects due to the difficulty of benchmarking transparency and accountability. This is the first comprehensive and integrated benchmark comprising over 18 subcategories, covering more than 30 datasets and 16 mainstream LLMs, including both proprietary and open-weight LLMs.
              (3) Last but not least, drawing from extensive experimental results , we have derived insightful findings. Our evaluation of trustworthiness in LLMs takes into account both the overall observation and individual findings based on each dimension, emphasizing the relationship between effectiveness and trustworthiness, the prevalent lack of real alignment in most LLMs, the disparity between proprietary and open-weight LLMs, and the opacity of current trustworthiness-related technologies. We aim to provide valuable insights for future research in this field, contributing to a more nuanced understanding of the trustworthiness landscape in large language models.
            </p>
          </div>
        </div>
        <h1 class="supportTitle">Empirical Findings</h1>
        <br>

        <h2 class="supportTitle2">Overall Perspective</h2>



        <div class="featurecard-container">
          <!-- Trustworthiness and Utility -->
          <div class="feature_1x1">
            <div class="featurecard">
              <h2>Trustworthiness Linked with Utility</h2>
            </div>
            <div class="description">
              <p><i>Trustworthiness is closely related to utility.</i> We have observed a close relationship between
                trustworthiness and utility, and they often have a positive relation in specific tasks. For example, in
                tasks like moral behavior classification and stereotype recognition, LLMs generally need to possess
                strong utility to understand the task's meaning and make correct choices. Additionally, the
                trustworthiness ranking of LLMs is often closely related to their ranking on utility-focused
                leaderboards.</p>
            </div>
          </div>

          <!-- Alignment of LLMs -->
          <div class="feature_1x1">
            <div class="featurecard">
              <h2>LLMs' Alignment Shortfall</h2>
            </div>
            <div class="description">
              <p><i>
                  We have found that many LLMs exhibit a certain degree of over-alignment (i.e., exaggerated safety),
                  which can compromise the trustworthiness of LLMs.</i> LLMs may identify many innocuous prompt contents
                as harmful, impacting their utility. For instance, Llama2-7b obtained a 57% of refusing to answer when
                the prompt is not harmful. Therefore, it is crucial to make LLMs aware of the real intent of the prompt
                itself in the alignment process instead of simply memorizing examples. This contributes to reducing the
                false positive rate when recognizing harmful content.
              </p>
            </div>
          </div>

          <!-- Performance Gap in Trustworthiness -->
          <div class="feature_1x1">
            <div class="featurecard">
              <h2>Trust Disparity: Closed vs. Open LLMs</h2>
            </div>
            <div class="description">
              <p><i>There is a performance gap of trustworthiness between proprietary LLMs and open-source LLMs.</i> A
                significant performance gap exists between open-source and proprietary LLMs in terms of trustworthiness.
                Proprietary LLMs tend to outperform open-source models, which raises concerns since open-source models
                are widely accessible. Surprisingly, some open-source LLMs like Llama2 show high trustworthiness,
                challenging this trend.</p>
            </div>
          </div>


          <!-- Transparency in Trustworthiness -->
          <div class="feature_1x1">

            <div class="featurecard">
              <h2>Imperative for Transparency in Trustworthy AI Technology</h2>
            </div>
            <div class="description">
              <p><i>Both the model itself and trustworthiness-related technology should be transparent (e.g.,
                  open-source).</i> The performance gap among different LLMs highlights the need for transparency in
                both the models and trustworthy technologies. Understanding the training mechanisms is fundamental in
                researching LLMs. While some proprietary LLMs show high trustworthiness, the lack of transparency in
                their technologies is a concern. Open sourcing trustworthy technologies can enhance LLM reliability and
                foster AI's benign development.</p>

            </div>
          </div>
        </div>


        <h2 class="supportTitle2">Section Perspective</h2>
        <br>
        <div class="featurecard-container">
          <div class="feature">

            <input type="checkbox" id="toggle" class="toggle">


            <div class="featurecard">
              <h2>Truthfulness</h2>

            </div>
            <div class="description">
              <p>Truthfulness means the accurate representation of information, facts, and results by an AI system. We
                have found that:</p>
              <ol>
                <li>Proprietary LLMs like GPT-4 and open-source LLMs like LLama2 struggle to provide truthful responses
                  when relying solely on their internal knowledge. This challenge can primarily be attributed to noise
                  in their training data, including misinformation or outdated information, and the lack of knowledge
                  generalization capability in the underlying Transformer architecture.</li>
                <li>Moreover, all LLMs encounter challenges in zero-shot commonsense reasoning tasks. This highlights
                  that LLMs may struggle with relatively straightforward tasks for humans to perform.</li>
                <li>Conversely, when assessing the performance of LLMs with augmented external knowledge, they exhibit
                  significantly improved results, surpassing the state-of-the-art performance reported in the original
                  datasets.</li>
                <li>We note a significant discrepancy among different hallucination tasks. Most LLMs exhibit fewer
                  hallucinations in multiple-choice question-answering tasks than in more open-ended tasks like
                  knowledge-grounded dialogue, likely attributed to prompt sensitivity.</li>
                <li>We also identify a positive correlation between sycophancy and adversarial actuality. Models
                  exhibiting lower levels of sycophancy demonstrate an ability to identify factual errors in user input
                  and highlight them effectively.</li>
              </ol>
            </div>
          </div>
          <div class="feature">

            <input type="checkbox" id="toggle#2" class="toggle">

            <div class="featurecard">
              <h2>Safety</h2>

            </div>
            <div class="description">
              <p>Safety ensures the outputs from LLMs should only engage users in a safe and healthy conversation. In
                our experiments, we have found that:</p>
              <ol>
                <li>The safety of most open-source LLMs still raises concerns and lags significantly behind proprietary
                  LLMs. For the most part, the safety of open-source LLMs is lower than that of proprietary LLMs in
                  terms of jailbreak, toxicity, and misuse.</li>
                <li>Importantly, LLMs cannot effectively resist various jailbreak attacks equally. We observed that
                  different jailbreak attacks have varying success rates against LLMs, with leetspeak attacks having the
                  highest success rate. Therefore, LLM developers should consider a comprehensive approach to defend
                  against different types of attacks.</li>
                <li>Most LLMs struggle to balance regular and excessive safety. LLMs with strong safety often exhibit
                  severely exaggerated safety, as seen in the Llama2 series and ERNIE, which suggests that most LLMs are
                  not really aligned and they may only memorize shallow alignment knowledge.</li>
              </ol>
            </div>
          </div>
          <div class="feature">
            <input type="checkbox" id="toggle#3" class="toggle">


            <div class="featurecard">
              <h2>Fairness</h2>

            </div>

            <div class="description">
              <p>Fairness is the quality or state of being fair, especially fair or impartial treatment. In our
                experiments, we have found that:</p>
              <ol>
                <li>The performance of most LLMs in identifying stereotypes is not satisfactory, with even the
                  best-performing GPT-4 having an overall accuracy of only 65%. When presented with sentences containing
                  stereotypes, the percentage of agreement of different LLMs varies widely, with the best performance at
                  only 0.5% agreement rate and the worst-performing one approaching an agreement rate of nearly 60%.
                </li>
                <li>Only a few LLMs, such as Oasst-12b and Vicuna-7b, exhibit fairness in handling disparagement; most
                  LLMs still display biases towards specific attributes when dealing with questions containing
                  disparaging tendencies.</li>
                <li>Regarding preferences, most LLMs perform very well on the plain baseline, maintaining objectivity
                  and neutrality or refusing to answer directly. However, when forced to choose an option, the
                  performance of LLMs significantly decreases.</li>
              </ol>
            </div>
          </div>
          <div class="feature">
            <input type="checkbox" id="toggle#4" class="toggle">

            <div class="featurecard">
              <h2>Robustness</h2>

            </div>
            <div class="description">
              <p>Robustness is the ability of a system to maintain its level of performance under a variety of
                circumstances. In our experiments, we have found that:</p>
              <ol>
                <li>The Llama2 series and most proprietary LLMs outperform other open-source models in traditional
                  downstream tasks.</li>
                <li>There is a significant variation in LLMs' performance in open-ended tasks. The worst-performing
                  model has an average semantic similarity of only 88% before and after perturbation, which is far below
                  the top performer at 97.64%.</li>
                <li>Regarding OOD robustness, LLMs also exhibit considerable variability in performance. The leading
                  model, GPT-4, shows a RtA (Refuse to Answer) rate of over 80% in OOD detection and an F1 score
                  averaging over 92% in OOD generalization. In contrast, the least effective models register a mere 0.4%
                  in RtA and F1 score of around 30%.</li>
              </ol>
            </div>
          </div>
          <div class="feature">
            <input type="checkbox" id="toggle#5" class="toggle">


            <div class="featurecard">
              <h2>Privacy</h2>

            </div>
            <div class="description">
              <p>Privacy is the norms and practices that help to safeguard human autonomy, identity, and dignity. In our
                experiments, we have found that:</p>
              <ol>
                <li>Most LLMs possess a certain level of privacy awareness, as the probability of LLMs refusing to
                  answer inquiries about private information dramatically increases when they are informed that they
                  must adhere to privacy policies.</li>
                <li>Pearson's correlation between humans and LLMs of agreement on privacy information usage varies a
                  lot. The best-performed ChatGPT archives a 0.665 correlation, however, the correlation of Oass-12b is
                  surprisingly less than zero, indicating a negative correlation with humans.</li>
                <li>We have observed that nearly all LLMs exhibit some information leakage on Enron Email Dataset.</li>
              </ol>
            </div>
          </div>
          <div class="feature">
            <input type="checkbox" id="toggle#6" class="toggle">


            <div class="featurecard">
              <h2>Machine Ethics</h2>

            </div>
            <div class="description">
              <p>Machine ethics ensure the moral behaviors of man-made machines that use artificial intelligence,
                otherwise known as artificial intelligent agents. In our experiments, we have found that:</p>
              <ol>
                <li>LLMs have already formed a particular set of moral values, but there is still a significant gap in
                  aligning completely with human ethics. The accuracy of most LLMs on implicit tasks with low-ambiguity
                  scenarios is below 70%, regardless of the dataset. When given a high-ambiguity scenario, the
                  performance varies a lot between different LLMs as the Llama2 series reaches an RtA of 99.9%, and some
                  are less than 70%.</li>
                <li>Regarding emotional awareness, LLMs demonstrate higher accuracy, with the best-performing LLMs being
                  GPT-4, which exceeds an accuracy rate of 94%.</li>
              </ol>
            </div>
          </div>


        </div>




        <br>
        <!--          <div class="feature">-->
        <!--            <h2>Taxonomy for TrustLLM</h2>-->
        <!--            <div class="flourish-embed flourish-hierarchy" data-src="visualisation/15357314">-->
        <!--              <script src="https://public.flourish.studio/resources/embed.js"></script>-->
        <!--            </div>-->
        <!--          </div>-->


      </div>

      <h1 class="supportTitle">Models</h1>


      <div class="content">
        <div class="content-table flex-column">
          <h2 class="supportTitle2">LLM Benchmark Details</h2>
          <br>
       

          <div class="flex-row">
            <div class="custom-table-container center add-top-margin-small">
              <table class="custom-table">
                <thead>
                  <tr>
                    <th>Model</th>
                    <th>Model Size</th>
                    <th>Open-Weight</th>
                    <th>Version</th>
                    <th>Creator</th>
                    <th>Source</th>
                  </tr>
                </thead>
                <tbody>
                  <tr class="bg-color-light-blue">
                    <td data-title="Model">GPT-3.5-turbo (ChatGPT)</td>
                    <td data-title="Model Size">unknown</td>
                    <td data-title="Open-Weight"><span class="bg-yellow-100 text-yellow-700 font-bold py-1 px-3 rounded-full">
                      No
                    </span>
                    <td data-title="Version">-</td>
                    <td data-title="Creator">OpenAI</td>
                    <td data-title="Source">OpenAI API</td>
                  </tr>
                  <tr>
                    <td data-title="Model">GPT-4</td>
                    <td data-title="Model Size">unknown</td>
                    <td data-title="Open-Weight"><span class="bg-yellow-100 text-yellow-700 font-bold py-1 px-3 rounded-full">
                      No
                    </span>
                    <td data-title="Version">-</td>
                    <td data-title="Creator">OpenAI</td>
                    <td data-title="Source">OpenAI API</td>
                  </tr>
                  <tr>
                    <td data-title="Model">ERNIE-3.5-turbo</td>
                    <td data-title="Model Size">unknown</td>
                    <td data-title="Open-Weight"><span class="bg-yellow-100 text-yellow-700 font-bold py-1 px-3 rounded-full">
                      No
                    </span>
                    </td>
                    <td data-title="Version">-</td>
                    <td data-title="Creator">Baidu Inc.</td>
                    <td data-title="Source">ERNIE API</td>
                  </tr>
                  <tr>
                    <td data-title="Model">text-bison-001 (PaLM 2)</td>
                    <td data-title="Model Size">unknown</td>
                    <td data-title="Open-Weight"><span class="bg-yellow-100 text-yellow-700 font-bold py-1 px-3 rounded-full">
                      No
                    </span>
                    <td data-title="Version">-</td>
                    <td data-title="Creator">Google</td>
                    <td data-title="Source">Google API</td>
                  </tr>
                  <tr>
                    <td data-title="Model">Llama2-7b</td>
                    <td data-title="Model Size">7b</td>
                    <td data-title="Open-Weight"><span class="bg-green-100 text-green-700 font-bold py-1 px-3 rounded-full">
                      Yes
                    </span>
                    <td data-title="Version">-</td>
                    <td data-title="Creator">Meta</td>
                    <td data-title="Source">HuggingFace</td>
                  </tr>
                  <tr>
                    <td data-title="Model">Llama2-13b</td>
                    <td data-title="Model Size">13b</td>
                                        <td data-title="Open-Weight"><span class="bg-green-100 text-green-700 font-bold py-1 px-3 rounded-full">
                      Yes
                    </span>
                    <td data-title="Version">-</td>
                    <td data-title="Creator">Meta</td>
                    <td data-title="Source">HuggingFace</td>
                  </tr>
                  <tr>
                    <td data-title="Model">Llama2-70b</td>
                    <td data-title="Model Size">70b</td>
                                        <td data-title="Open-Weight"><span class="bg-green-100 text-green-700 font-bold py-1 px-3 rounded-full">
                      Yes
                    </span>
                    <td data-title="Version">-</td>
                    <td data-title="Creator">Meta</td>
                    <td data-title="Source">HuggingFace</td>
                  </tr>
                  <tr>
                    <td data-title="Model">Vicuna-33b</td>
                    <td data-title="Model Size">33b</td>
                                        <td data-title="Open-Weight"><span class="bg-green-100 text-green-700 font-bold py-1 px-3 rounded-full">
                      Yes
                    </span>
                    <td data-title="Version">v1.3</td>
                    <td data-title="Creator">LMSYS</td>
                    <td data-title="Source">HuggingFace</td>
                  </tr>
                  <tr>
                    <td data-title="Model">Vicuna-13b</td>
                    <td data-title="Model Size">13b</td>
                                        <td data-title="Open-Weight"><span class="bg-green-100 text-green-700 font-bold py-1 px-3 rounded-full">
                      Yes
                    </span>
                    <td data-title="Version">v1.3</td>
                    <td data-title="Creator">LMSYS</td>
                    <td data-title="Source">HuggingFace</td>
                  </tr>
                  <tr>
                    <td data-title="Model">Vicuna-7b</td>
                    <td data-title="Model Size">7b</td>
                                        <td data-title="Open-Weight"><span class="bg-green-100 text-green-700 font-bold py-1 px-3 rounded-full">
                      Yes
                    </span>
                    <td data-title="Version">v1.3</td>
                    <td data-title="Creator">LMSYS</td>
                    <td data-title="Source">HuggingFace</td>
                  </tr>
                  <!-- ...continue for other rows... -->
                  <tr>
                    <td data-title="Model">Koala-13b</td>
                    <td data-title="Model Size">13b</td>
                                        <td data-title="Open-Weight"><span class="bg-green-100 text-green-700 font-bold py-1 px-3 rounded-full">
                      Yes
                    </span>
                    <td data-title="Version">-</td>
                    <td data-title="Creator">UCB</td>
                    <td data-title="Source">HuggingFace</td>
                  </tr>

                  <tr>
                    <td data-title="Model">ChatGLM2</td>
                    <td data-title="Model Size">6b</td>
                                        <td data-title="Open-Weight"><span class="bg-green-100 text-green-700 font-bold py-1 px-3 rounded-full">
                      Yes
                    </span>
                    <td data-title="Version">v1.0</td>
                    <td data-title="Creator">Tsinghua & Zhipu</td>
                    <td data-title="Source">HuggingFace</td>
                  </tr>
                  <!-- ...continue for other rows... -->
                  <tr>
                    <td data-title="Model">Baichuan-13b</td>
                    <td data-title="Model Size">13b</td>
                                        <td data-title="Open-Weight"><span class="bg-green-100 text-green-700 font-bold py-1 px-3 rounded-full">
                      Yes
                    </span>
                    <td data-title="Version">-</td>
                    <td data-title="Creator">Baichuan Inc.</td>
                    <td data-title="Source">HuggingFace</td>
                  </tr>

                  <tr>
                    <td data-title="Model">Wizardlm-13b</td>
                    <td data-title="Model Size">13b</td>
                                        <td data-title="Open-Weight"><span class="bg-green-100 text-green-700 font-bold py-1 px-3 rounded-full">
                      Yes
                    </span>
                    <td data-title="Version">v1.2</td>
                    <td data-title="Creator">Microsoft</td>
                    <td data-title="Source">HuggingFace</td>
                  </tr>
                  <tr>
                    <td data-title="Model">Oasst-12b</td>
                    <td data-title="Model Size">12b</td>
                                        <td data-title="Open-Weight"><span class="bg-green-100 text-green-700 font-bold py-1 px-3 rounded-full">
                      Yes
                    </span>
                    <td data-title="Version">-</td>
                    <td data-title="Creator">LAION</td>
                    <td data-title="Source">HuggingFace</td>
                  </tr>
                  <!-- Repeat for other rows, alternating color for LightCyan rows -->
                </tbody>
              </table>
            </div>
          </div>
        </div>
      </div>
    </div>

    <h1 class="supportTitle">Task & Dataset</h1>

    <div class="content">
      <div class="content-table flex-column">
        <h2 class="supportTitle2"> Datasets and metrics</h2>
        <br>
        <div class="flex-row">
          <div class="custom-table-container center add-top-margin-small">
            <table class="custom-table">
              <caption>Datasets and metrics in TrustLLM. ✓ means the dataset exists and ✗ means the dataset is
                first proposed in the TrustLLM benchmark.</caption>
              <thead>
                <tr class="bg-color-blue">
                  <th>Dataset</th>
                  <th>Description</th>
                  <th>Num.</th>
                  <th>Exist?</th>
                  <th>Section</th>
                </tr>
              </thead>
              <tbody>
                <!-- Previous rows -->
                <tr>
                  <td class="text-left">SQuAD2.0</td>
                  <td class="text-left">It combines questions in SQuAD1.1 with over 50,000 unanswerable questions.
                  </td>
                  <td>100</td>
                  <td>✓</td>
                  <td>Misinformation</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">CODAH</td>
                  <td class="text-left">It contains 28,000 commonsense questions.</td>
                  <td>100</td>
                  <td>✓</td>
                  <td>Misinformation</td>
                </tr>
                <tr>
                  <td class="text-left">HotpotQA</td>
                  <td class="text-left">It contains 113k Wikipedia-based question-answer pairs for complex multi-hop
                    reasoning.</td>
                  <td>100</td>
                  <td>✓</td>
                  <td>Misinformation</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">AdversarialQA</td>
                  <td class="text-left">It contains 30,000 adversarial reading comprehension question-answer pairs.
                  </td>
                  <td>100</td>
                  <td>✓</td>
                  <td>Misinformation</td>
                </tr>
                <tr>
                  <td class="text-left">Climate-FEVER</td>
                  <td class="text-left">It contains 7,675 climate change-related claims manually curated by human
                    fact-checkers.</td>
                  <td>100</td>
                  <td>✓</td>
                  <td>Misinformation</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">SciFact</td>
                  <td class="text-left">It contains 1,400 expert-written scientific claims pairs with evidence
                    abstracts.</td>
                  <td>100</td>
                  <td>✓</td>
                  <td>Misinformation</td>
                </tr>
                <tr>
                  <td class="text-left">COVID-Fact</td>
                  <td class="text-left">It contains 4,086 real-world COVID claims.</td>
                  <td>100</td>
                  <td>✓</td>
                  <td>Misinformation</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">HealthVer</td>
                  <td class="text-left">It contains 14,330 health-related claims against scientific articles.</td>
                  <td>100</td>
                  <td>✓</td>
                  <td>Misinformation</td>
                </tr>
                <tr>
                  <td class="text-left">TruthfulQA</td>
                  <td class="text-left">The multiple-choice questions to evaluate whether a language model is truthful
                    in generating answers to questions.</td>
                  <td>352</td>
                  <td>✓</td>
                  <td>Hallucination</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">HaluEval</td>
                  <td class="text-left">It contains 35,000 generated and human-annotated hallucinated samples.</td>
                  <td>300</td>
                  <td>✓</td>
                  <td>Hallucination</td>
                </tr>
                <tr>
                  <td class="text-left">LM-exp-sycophancy</td>
                  <td class="text-left">A dataset consists of human questions with one sycophancy response example and
                    one non-sycophancy response example.</td>
                  <td>179</td>
                  <td>✓</td>
                  <td>Sycophancy</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">Opinion pairs</td>
                  <td class="text-left">It contains 120 pairs of opposite opinions.</td>
                  <td>240</td>
                  <td>✗</td>
                  <td>Sycophancy</td>
                </tr>

                <tr>
                  <td class="text-left">WinoBias</td>
                  <td class="text-left">It contains 3,160 sentences, split for development and testing, created by
                    researchers familiar with the project.</td>
                  <td>734</td>
                  <td>✓</td>
                  <td>Stereotype</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">StereoSet</td>
                  <td class="text-left">It contains the sentences that measure model preferences across gender, race,
                    religion, and profession.</td>
                  <td>734</td>
                  <td>✓</td>
                  <td>Stereotype</td>
                </tr>
                <tr>
                  <td class="text-left">Adult</td>
                  <td class="text-left">The dataset, containing attributes like sex, race, age, education, work hours,
                    and work type, is utilized to predict salary levels for individuals.</td>
                  <td>810</td>
                  <td>✓</td>
                  <td>Disparagement</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">Jailbraek Trigger</td>
                  <td class="text-left">The dataset contains the prompts based on 13 jailbreak attacks.</td>
                  <td>1300</td>
                  <td>✗</td>
                  <td>Jailbreak, Toxicity</td>
                </tr>
                <tr>
                  <td class="text-left">Misuse (additional)</td>
                  <td class="text-left">This dataset contains prompts crafted to assess how LLMs react when confronted
                    by attackers or malicious users seeking to exploit the model for harmful purposes.</td>
                  <td>261</td>
                  <td>✗</td>
                  <td>Misuse</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">Do-Not-Answer</td>
                  <td class="text-left">It is curated and filtered to consist only of prompts to which responsible
                    LLMs do not answer.</td>
                  <td>344 + 95</td>
                  <td>✓</td>
                  <td>Misuse, Stereotype</td>
                </tr>
                <tr>
                  <td class="text-left">AdvGLUE</td>
                  <td class="text-left">A multi-task dataset with different adversarial attacks.</td>
                  <td>912</td>
                  <td>✓</td>
                  <td>Natural Noise</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">AdvInstruction</td>
                  <td class="text-left">600 instructions generated by 11 perturbation methods.</td>
                  <td>1200</td>
                  <td>✗</td>
                  <td>Natural Noise</td>
                </tr>
                <tr>
                  <td class="text-left">ToolE</td>
                  <td class="text-left">A dataset with the users' queries which may trigger LLMs to use external
                    tools.</td>
                  <td>241</td>
                  <td>✓</td>
                  <td>Out of Domain (OOD)</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">Flipkart</td>
                  <td class="text-left">A product review dataset, collected starting from December 2022.</td>
                  <td>400</td>
                  <td>✓</td>
                  <td>Out of Domain (OOD)</td>
                </tr>
                <tr>
                  <td class="text-left">DDXPlus</td>
                  <td class="text-left">A 2022 medical diagnosis dataset comprising synthetic data representing about
                    1.3 million patient cases.</td>
                  <td>100</td>
                  <td>✓</td>
                  <td>Out of Domain (OOD)</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">ETHICS</td>
                  <td class="text-left">It contains numerous morally relevant scenarios descriptions and their moral
                    correctness.</td>
                  <td>500</td>
                  <td>✓</td>
                  <td>Implicit Ethics</td>
                </tr>
                <tr>
                  <td class="text-left">Social Chemistry 101</td>
                  <td class="text-left">It contains various social norms, each consisting of an action and its label.
                  </td>
                  <td>500</td>
                  <td>✓</td>
                  <td>Implicit Ethics</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">MoralChoice</td>
                  <td class="text-left">It consists of different contexts with morally correct and wrong actions.</td>
                  <td>668</td>
                  <td>✓</td>
                  <td>Explicit Ethics</td>
                </tr>
                <tr>
                  <td class="text-left">ConfAIde</td>
                  <td class="text-left">It contains the description of how information is used.</td>
                  <td>196</td>
                  <td>✓</td>
                  <td>Privacy Awareness</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">Privacy Awareness</td>
                  <td class="text-left">It includes different privacy information queries about various scenarios.
                  </td>
                  <td>280</td>
                  <td>✗</td>
                  <td>Privacy Awareness</td>
                </tr>
                <tr>
                  <td class="text-left">Enron Email</td>
                  <td class="text-left">It contains approximately 500,000 emails generated by employees of the Enron
                    Corporation.</td>
                  <td>400</td>
                  <td>✓</td>
                  <td>Privacy Leakage</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td class="text-left">Xstest</td>
                  <td class="text-left">It's a test suite for identifying exaggerated safety behaviors in LLMs.</td>
                  <td>200</td>
                  <td>✓</td>
                  <td>Exaggerated Safety</td>
                </tr>


              </tbody>
            </table>
          </div>
        </div>
        <br><br>
        <h2 class="supportTitle2"> Task Overview</h2> <br>
        <div class="flex-row">
          <div class="custom-table-container center add-top-margin-small">
            <table class="custom-table">
              <caption>
                Task Overview. <span>&#9675;</span> means automatic evaluation, <span>&#9679;</span> means manual
                evaluation, and <span>&#9680;</span> means semi-automatic evaluation. More trustworthy LLMs are
                expected to have a higher value of the metrics with &uarr; and a lower value of the metrics with
                &darr;.
              </caption>
              <thead>
                <tr class="bg-color-blue">
                  <th>Task Name</th>
                  <th class="text-center">Metrics</th>
                  <th class="text-center">Type</th>
                  <th class="text-center">Eval</th>
                  <th>Section</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Closed-book QA</td>
                  <td class="text-center">Accuracy (&uarr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9675;</td>
                  <td>Misinformation(Internal)</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td>Fact-Checking</td>
                  <td class="text-center">Macro F-1 (&uarr;)</td>
                  <td class="text-center">Classification</td>
                  <td class="text-center">&#9679;</td>
                  <td>Misinformation(External)</td>
                </tr>
                <tr>
                  <td>Multiple Choice QA</td>
                  <td class="text-center">Accuracy (&uarr;)</td>
                  <td class="text-center">Classification</td>
                  <td class="text-center">&#9679;</td>
                  <td>Hallucination</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td>Hallucination Classification</td>
                  <td class="text-center">Accuracy (&uarr;)</td>
                  <td class="text-center">Classification</td>
                  <td class="text-center">&#9679;</td>
                  <td>Hallucination</td>
                </tr>
                <tr>
                  <td>Persona Sycophancy</td>
                  <td class="text-center">Embedding similarity (&uarr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9680;</td>
                  <td>Sycophancy</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td>Opinion Sycophancy</td>
                  <td class="text-center">Percentage change (&darr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9675;</td>
                  <td>Sycophancy</td>
                </tr>
                <tr>
                  <td>Factuality Correction</td>
                  <td class="text-center">Percentage change (&uarr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9675;</td>
                  <td>Adversarial Factuality</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td>Jailbreak Attack Evaluation</td>
                  <td class="text-center">RtA (&uarr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9675;</td>
                  <td>Jailbreak</td>
                </tr>
                <tr>
                  <td>Toxicity Measurement</td>
                  <td class="text-center">Toxicity Value (&darr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9679;</td>
                  <td>Toxicity</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td>Misuse Evaluation</td>
                  <td class="text-center">RtA (&uarr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9675;</td>
                  <td>Misuse</td>
                </tr>
                <tr>
                  <td>Exaggerated Safety Evaluation</td>
                  <td class="text-center">RtA (&darr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9675;</td>
                  <td>Exaggerated Safety</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td>Agreement on Stereotypes</td>
                  <td class="text-center">Accuracy (&uarr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9680;</td>
                  <td>Stereotype</td>
                </tr>
                <tr>
                  <td>Recognition of Stereotypes</td>
                  <td class="text-center">Agreement Percentage (&darr;)</td>
                  <td class="text-center">Classification</td>
                  <td class="text-center">&#9680;</td>
                  <td>Stereotype</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td>Stereotype Query Test</td>
                  <td class="text-center">RtA (&uarr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9675;</td>
                  <td>Stereotype</td>
                </tr>
                <tr>
                  <td>Preference Selection</td>
                  <td class="text-center">RtA (&uarr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9675;</td>
                  <td>Preference</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td>Salary Prediction</td>
                  <td class="text-center">p-value (&uarr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9679;</td>
                  <td>Disparagement</td>
                </tr>
                <tr>
                  <td>Adversarial Perturbation in Downstream Tasks</td>
                  <td class="text-center">ASR (&darr;), RS (&uarr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9680;</td>
                  <td>Natural Noise</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td>Adversarial Perturbation in Open-Ended Tasks</td>
                  <td class="text-center">Embedding similarity (&uarr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9680;</td>
                  <td>Natural Noise</td>
                </tr>
                <tr>
                  <td>OOD Detection</td>
                  <td class="text-center">RtA (&uarr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9675;</td>
                  <td>Out of Domain (OOD)</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td>OOD Generalization</td>
                  <td class="text-center">Micro F1 (&uarr;)</td>
                  <td class="text-center">Classification</td>
                  <td class="text-center">&#9675;</td>
                  <td>Out of Domain (OOD)</td>
                </tr>
                <tr>
                  <td>Agreement on Privacy Information</td>
                  <td class="text-center">Pearson’s correlation (&uarr;)</td>
                  <td class="text-center">Classification</td>
                  <td class="text-center">&#9679;</td>
                  <td>Privacy Awareness</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td>Privacy Scenario Test</td>
                  <td class="text-center">RtA (&uarr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9675;</td>
                  <td>Privacy Awareness</td>
                </tr>
                <tr>
                  <td>Probing Privacy Information Usage</td>
                  <td class="text-center">RtA (&uarr;), Accuracy (&darr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9680;</td>
                  <td>Privacy Leakage</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td>Moral Action Judgement</td>
                  <td class="text-center">Accuracy (&uarr;)</td>
                  <td class="text-center">Classification</td>
                  <td class="text-center">&#9680;</td>
                  <td>Implicit Ethics</td>
                </tr>
                <tr>
                  <td>Moral Reaction Selection (Low-Ambiguity)</td>
                  <td class="text-center">Accuracy (&uarr;)</td>
                  <td class="text-center">Classification</td>
                  <td class="text-center">&#9680;</td>
                  <td>Explicit Ethics</td>
                </tr>
                <tr class="bg-color-light-blue">
                  <td>Moral Reaction Selection (High-Ambiguity)</td>
                  <td class="text-center">RtA (&uarr;)</td>
                  <td class="text-center">Generation</td>
                  <td class="text-center">&#9675;</td>
                  <td>Explicit Ethics</td>
                </tr>
                <tr>
                  <td>Emotion Classification</td>
                  <td class="text-center">Accuracy (&uarr;)</td>
                  <td class="text-center">Classification</td>
                  <td class="text-center">&#9679;</td>
                  <td>Emotional Awareness</td>
                </tr>

              </tbody>
            </table>
          </div>
        </div>
      </div>
    </div>

    <!--Start Text with Adaptive Image-->
    <h1 class="supportTitle">Ranking Card</h1>
    <br>
    <div class="center-container">
      <img src="img/rank_card_00.png" class="title-icon2" alt="Rank Card">
    </div>
    <!--End Text with Adaptive Image-->
    <!-------------------------------------------------------------------------------------------->
  </div>
  </div>
  <h1 class="supportTitle">Citation</h1>
  <br>
  <pre class="bibtax">@
        title={TrsLM s},
        author={
        year={2023}
        }
              </pre>
  <br>
  </div>

  </div>
  </div>
  <div id="supportContainer">
    <h1 class="supportTitle">TrustLLM Team</h1>
    <br>

    <div id="logoContainer">
      <img src="img/logos/Lehigh-University-logo.png" alt="School 1" class="schoolLogo">
      <img src="img/logos/W&M.png" alt="School 3" class="schoolLogo">
      <img src="img/logos/stanford.png" alt="School 3" class="schoolLogo">
      <img src="img/logos/UCLA.jpeg" alt="School 3" class="schoolLogo">
      <img src="img/logos/CMU.png" alt="School 3" class="schoolLogo">
      <img src="img/logos/UIUC.png" alt="School 3" class="schoolLogo">
      <img src="img/logos/TAMU.png" alt="School 3" class="schoolLogo">
      <img src="img/logos/ND.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/duke.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/UMD.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/JHU.jpeg" alt="School 2" class="schoolLogo">
      <img src="img/logos/UIC.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/UGA.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/MSU.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/UWM.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/UCSB.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/uconn.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/vt.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/IIT.gif" alt="School 2" class="schoolLogo">
      <img src="img/logos/USC.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/CISPA.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/MGH.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/Microsoft.png" alt="School 3" class="schoolLogo">
      <img src="img/logos/samsung.webp" alt="School 2" class="schoolLogo">
      <img src="img/logos/IBM.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/Salesforce.png" alt="School 2" class="schoolLogo">
      <img src="img/logos/drexel.jpg" alt="School 2" class="schoolLogo">
    </div>


  </div>
  <div class="footer-container"></div>
  </div>
</body>

</html>